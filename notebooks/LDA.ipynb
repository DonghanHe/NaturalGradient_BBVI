{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_parameters = torch.empty(31, 73, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 0.0000e+00, 1.9649e-24,  ..., 1.7226e+11, 1.7988e-19,\n        1.7894e-19])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(variational_parameters).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\ntensor([[ 0.0078, -0.0089, -0.0080,  ...,  0.0021, -0.0037,  0.0192],\n        [-0.0124, -0.0009,  0.0039,  ..., -0.0019,  0.0230,  0.0007],\n        [ 0.0037, -0.0036, -0.0044,  ..., -0.0118,  0.0211,  0.0174],\n        ...,\n        [-0.0031, -0.0006,  0.0099,  ..., -0.0058,  0.0018, -0.0248],\n        [ 0.0076, -0.0120,  0.0019,  ...,  0.0070, -0.0080, -0.0178],\n        [ 0.0135,  0.0045, -0.0190,  ..., -0.0103,  0.0046, -0.0210]],\n       requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_logits = torch.nn.Parameter(torch.FloatTensor(8447, 30, ))\n",
    "torch.nn.init.xavier_uniform_(d_logits, 1)\n",
    "t_logits = torch.nn.Parameter(torch.FloatTensor(30, 3012, ))\n",
    "torch.nn.init.xavier_normal_(t_logits, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0266, grad_fn=<MinBackward1>),\n tensor(0.0266, grad_fn=<MaxBackward1>))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_logits.min(), d_logits.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0562, grad_fn=<MinBackward1>),\n tensor(0.0521, grad_fn=<MaxBackward1>))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_logits.min(), t_logits.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0078, -0.0089, -0.0080,  ...,  0.0021, -0.0037,  0.0192],\n        [-0.0124, -0.0009,  0.0039,  ..., -0.0019,  0.0230,  0.0007],\n        [ 0.0037, -0.0036, -0.0044,  ..., -0.0118,  0.0211,  0.0174],\n        ...,\n        [-0.0031, -0.0006,  0.0099,  ..., -0.0058,  0.0018, -0.0248],\n        [ 0.0076, -0.0120,  0.0019,  ...,  0.0070, -0.0080, -0.0178],\n        [ 0.0135,  0.0045, -0.0190,  ..., -0.0103,  0.0046, -0.0210]],\n       grad_fn=<ClampBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(t_logits, max=1e3, min=-1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.any(torch.isnan(torch.clamp(t_logits, max=1e3, min=-1e3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus, common_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 0,\n 'eps': 8,\n 'graph': 10,\n 'human': 1,\n 'interface': 2,\n 'minors': 11,\n 'response': 3,\n 'survey': 4,\n 'system': 5,\n 'time': 6,\n 'trees': 9,\n 'user': 7}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(a,b,c):\n",
    "    return print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "func(*(1,2), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, = (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t = torch.arange(500, dtype=torch.float32).reshape((5, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gather = np.array([[1, 0, 0], \n",
    "                            [1, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gathered = np.take_along_axis(test_t.reshape((1, 5, 100)), test_gather.reshape((2, 1, 3)), axis=-1)\n",
    "normed = gathered/torch.sum(gathered, dim=1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0010, 0.0000, 0.0000],\n         [0.1005, 0.0000, 0.0000],\n         [0.2000, 0.0000, 0.0000],\n         [0.2995, 0.0000, 0.0000],\n         [0.3990, 0.0000, 0.0000]],\n\n        [[0.0010, 0.0010, 0.0000],\n         [0.1005, 0.1005, 0.0000],\n         [0.2000, 0.2000, 0.0000],\n         [0.2995, 0.2995, 0.0000],\n         [0.3990, 0.3990, 0.0000]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(normed * torch.unsqueeze(torch.tensor(test_gather), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-901206.8125)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(-0.5*(normed - gathered)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(901206.8125)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MSELoss(reduction='sum')(normed, gathered)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n          12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,\n          24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,\n          36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,\n          48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,\n          60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n          72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,\n          84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,\n          96.,  97.,  98.,  99.],\n        [100., 101., 102., 103., 104., 105., 106., 107., 108., 109., 110., 111.,\n         112., 113., 114., 115., 116., 117., 118., 119., 120., 121., 122., 123.,\n         124., 125., 126., 127., 128., 129., 130., 131., 132., 133., 134., 135.,\n         136., 137., 138., 139., 140., 141., 142., 143., 144., 145., 146., 147.,\n         148., 149., 150., 151., 152., 153., 154., 155., 156., 157., 158., 159.,\n         160., 161., 162., 163., 164., 165., 166., 167., 168., 169., 170., 171.,\n         172., 173., 174., 175., 176., 177., 178., 179., 180., 181., 182., 183.,\n         184., 185., 186., 187., 188., 189., 190., 191., 192., 193., 194., 195.,\n         196., 197., 198., 199.],\n        [200., 201., 202., 203., 204., 205., 206., 207., 208., 209., 210., 211.,\n         212., 213., 214., 215., 216., 217., 218., 219., 220., 221., 222., 223.,\n         224., 225., 226., 227., 228., 229., 230., 231., 232., 233., 234., 235.,\n         236., 237., 238., 239., 240., 241., 242., 243., 244., 245., 246., 247.,\n         248., 249., 250., 251., 252., 253., 254., 255., 256., 257., 258., 259.,\n         260., 261., 262., 263., 264., 265., 266., 267., 268., 269., 270., 271.,\n         272., 273., 274., 275., 276., 277., 278., 279., 280., 281., 282., 283.,\n         284., 285., 286., 287., 288., 289., 290., 291., 292., 293., 294., 295.,\n         296., 297., 298., 299.],\n        [300., 301., 302., 303., 304., 305., 306., 307., 308., 309., 310., 311.,\n         312., 313., 314., 315., 316., 317., 318., 319., 320., 321., 322., 323.,\n         324., 325., 326., 327., 328., 329., 330., 331., 332., 333., 334., 335.,\n         336., 337., 338., 339., 340., 341., 342., 343., 344., 345., 346., 347.,\n         348., 349., 350., 351., 352., 353., 354., 355., 356., 357., 358., 359.,\n         360., 361., 362., 363., 364., 365., 366., 367., 368., 369., 370., 371.,\n         372., 373., 374., 375., 376., 377., 378., 379., 380., 381., 382., 383.,\n         384., 385., 386., 387., 388., 389., 390., 391., 392., 393., 394., 395.,\n         396., 397., 398., 399.],\n        [400., 401., 402., 403., 404., 405., 406., 407., 408., 409., 410., 411.,\n         412., 413., 414., 415., 416., 417., 418., 419., 420., 421., 422., 423.,\n         424., 425., 426., 427., 428., 429., 430., 431., 432., 433., 434., 435.,\n         436., 437., 438., 439., 440., 441., 442., 443., 444., 445., 446., 447.,\n         448., 449., 450., 451., 452., 453., 454., 455., 456., 457., 458., 459.,\n         460., 461., 462., 463., 464., 465., 466., 467., 468., 469., 470., 471.,\n         472., 473., 474., 475., 476., 477., 478., 479., 480., 481., 482., 483.,\n         484., 485., 486., 487., 488., 489., 490., 491., 492., 493., 494., 495.,\n         496., 497., 498., 499.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_t.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2040)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BCELoss()(torch.tensor(0.1), torch.tensor(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "?torch.nn.BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 94.,   7.,  81.,  16.,  49.,  60.,   0.,  17.,  66.,   5.],\n        [194., 107., 181., 116., 149., 160., 100., 117., 166., 105.],\n        [294., 207., 281., 216., 249., 260., 200., 217., 266., 205.],\n        [394., 307., 381., 316., 349., 360., 300., 317., 366., 305.],\n        [494., 407., 481., 416., 449., 460., 400., 417., 466., 405.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 100, size=10, replace=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82,  4, 22, 35, 28, 96, 45, 48, 95, 65])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(np.arange(100), size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
